{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eaf538d-4baa-4502-9872-7731bc3fcede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import hashlib\n",
    "import tarfile\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from dataset import LFWDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64173e40-3f74-404c-80f3-d23ca744526c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNet2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet2, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc_11 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
    "        self.enc_12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoder\n",
    "        self.dec_21 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.dec_22 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.upconv1 = nn.ConvTranspose2d(64, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = F.relu(self.enc_11(x))\n",
    "        x2 = F.relu(self.enc_12(x1))\n",
    "        x = self.pool1(x2)\n",
    "\n",
    "        # Decoder\n",
    "        x = F.relu(self.dec_21(x))\n",
    "        x = F.relu(self.dec_22(x))\n",
    "        x = self.upconv1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90ba2fc-a86b-4cfd-b42f-489f36f7d055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2(\n",
       "  (enc_11): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (enc_12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dec_21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dec_22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv1): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform=None\n",
    "train_dataset = LFWDataset(base_folder='..\\cvdl_lab_4\\lfw_dataset', transforms=transform, download=False, split_name='train')\n",
    "test_dataset = LFWDataset(base_folder='..\\cvdl_lab_4\\lfw_dataset', transforms=transform, download=False, split_name='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = UNet2(in_channels=3, out_channels=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b255adbb-b697-4253-ae3d-314ba0e52860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [08:27<00:00, 13.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.9846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:31<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [08:36<00:00, 13.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:31<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [07:25<00:00, 12.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.5534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:29<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [07:21<00:00, 11.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.5519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [07:24<00:00, 12.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.5281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [07:21<00:00, 11.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.5267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [07:22<00:00, 11.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.5149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [07:21<00:00, 11.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.5164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████████████████████████████████████████████████████████████████| 37/37 [07:32<00:00, 12.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.4998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|█████████████████████████████████████████████████████████████████████| 37/37 [08:18<00:00, 13.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.4871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:32<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        inputs, targets = inputs.to(device).float(), targets.to(device)\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        targets_list = targets.tolist() if isinstance(targets, torch.Tensor) else targets\n",
    "\n",
    "        # Map target values to valid class indices\n",
    "        value_mapping = {29: 0, 76: 1, 150: 2}\n",
    "        # Use torch.where to map values\n",
    "        targets = torch.where(targets == 29, torch.tensor(value_mapping[29]), \n",
    "                            torch.where(targets == 76, torch.tensor(value_mapping[76]), \n",
    "                                        torch.tensor(value_mapping[150])))\n",
    "\n",
    "        # Convert target tensor to Long\n",
    "        targets = targets.long()\n",
    "        outputs = model(inputs)\n",
    "        #print(np.unique(targets))\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Validation\"):\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device)\n",
    "            inputs = inputs.permute(0, 3, 1, 2)\n",
    "            value_mapping = {29: 0, 76: 1, 150: 2}\n",
    "            # Use torch.where to map values\n",
    "            targets = torch.where(targets == 29, torch.tensor(value_mapping[29]), \n",
    "                            torch.where(targets == 76, torch.tensor(value_mapping[76]), \n",
    "                                        torch.tensor(value_mapping[150])))\n",
    "\n",
    "            # Convert target tensor to Long\n",
    "            targets = targets.long()\n",
    "            outputs = model(inputs)\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "            # Update total_samples and total_correct\n",
    "            total_samples += targets.numel()\n",
    "            total_correct += (predicted == targets).sum().item()\n",
    "\n",
    "\n",
    "    # Print validation metrics\n",
    "    print(f\"Validation Accuracy: {total_correct / total_samples:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6264ec5-1cdb-47c2-899a-2685ea2cd5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"final_scripted_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f4d4f1-a8f0-4ba4-8767-51d680897604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acb9f2ca-142e-4189-af30-ae05af3c29b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_model = torch.jit.load(\"final_scripted_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe317c00-3690-47ce-8254-3c0086197dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def segment_image(input_image):\n",
    "    image_array = np.array(input_image)\n",
    "    image_tensor = torch.unsqueeze(torch.transpose(torch.tensor(input_image), 0, 2), 0).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = my_model(image_tensor)\n",
    "\n",
    "    predicted_mask = torch.argmax(output, dim=1).squeeze().numpy()\n",
    "    predicted_mask_rotated = np.rot90(predicted_mask, k=-1)\n",
    "    predicted_mask_final = np.fliplr(predicted_mask_rotated)\n",
    "    \n",
    "    predicted_mask_final = (predicted_mask_final * 255).astype(np.uint8)\n",
    "    return predicted_mask_final\n",
    "\n",
    "# Gradio Interface\n",
    "ui = gr.Interface(\n",
    "    fn=segment_image, \n",
    "    inputs=gr.Image(),\n",
    "    outputs=gr.Image(),\n",
    "    examples=['celeb_inputs/celeb1.jpg', \n",
    "              'celeb_inputs/celeb2.jpg', \n",
    "              'celeb_inputs/celeb3.jpg',\n",
    "              'celeb_inputs/celeb4.jpg',\n",
    "              'celeb_inputs/celeb5.jpg']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e5f9d6-ec16-4899-9f7b-37ac5c256e16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f04234e2-2809-4783-92aa-e30d7eab3dce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2(\n",
       "  (enc_11): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (enc_12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dec_21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dec_22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv1): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform=None\n",
    "train_dataset = LFWDataset(base_folder='..\\cvdl_lab_4\\lfw_dataset', transforms=transform, download=False, split_name='train')\n",
    "test_dataset = LFWDataset(base_folder='..\\cvdl_lab_4\\lfw_dataset', transforms=transform, download=False, split_name='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "model = UNet2(in_channels=3, out_channels=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7291bb33-eff7-4972-918d-0d1be3ab9cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:31<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:28<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.5222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:32<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:28<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:33<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:27<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.4712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:31<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:23<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:32<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:27<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:32<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:25<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.4432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:31<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:25<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.4413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:32<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████████████████████████████| 586/586 [07:23<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.4328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:31<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|███████████████████████████████████████████████████████████████████| 586/586 [07:20<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.4302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 147/147 [00:31<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        inputs, targets = inputs.to(device).float(), targets.to(device)\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        targets_list = targets.tolist() if isinstance(targets, torch.Tensor) else targets\n",
    "\n",
    "        # Map target values to valid class indices\n",
    "        value_mapping = {29: 0, 76: 1, 150: 2}\n",
    "        # Use torch.where to map values\n",
    "        targets = torch.where(targets == 29, torch.tensor(value_mapping[29]), \n",
    "                            torch.where(targets == 76, torch.tensor(value_mapping[76]), \n",
    "                                        torch.tensor(value_mapping[150])))\n",
    "\n",
    "        # Convert target tensor to Long\n",
    "        targets = targets.long()\n",
    "        outputs = model(inputs)\n",
    "        #print(np.unique(targets))\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Validation\"):\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device)\n",
    "            inputs = inputs.permute(0, 3, 1, 2)\n",
    "            value_mapping = {29: 0, 76: 1, 150: 2}\n",
    "            # Use torch.where to map values\n",
    "            targets = torch.where(targets == 29, torch.tensor(value_mapping[29]), \n",
    "                            torch.where(targets == 76, torch.tensor(value_mapping[76]), \n",
    "                                        torch.tensor(value_mapping[150])))\n",
    "\n",
    "            # Convert target tensor to Long\n",
    "            targets = targets.long()\n",
    "            outputs = model(inputs)\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "            # Update total_samples and total_correct\n",
    "            total_samples += targets.numel()\n",
    "            total_correct += (predicted == targets).sum().item()\n",
    "\n",
    "\n",
    "    # Print validation metrics\n",
    "    print(f\"Validation Accuracy: {total_correct / total_samples:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e13e9b55-d3c6-4139-a2df-9852ef55c9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"var2_scripted_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdce43-4170-4bdd-9bc1-4da8519536d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
