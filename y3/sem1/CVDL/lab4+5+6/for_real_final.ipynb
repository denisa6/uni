{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7886480f-904e-4e70-a031-93c9bde614a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import hashlib\n",
    "import tarfile\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from dataset import LFWDataset\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf484e9b-2ee3-4387-ac31-dfa5fc2f71be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_model = torch.jit.load(\"var2_scripted_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c719354b-5d81-4c3b-8d1d-2a106e117ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def segment_image(input_image):\n",
    "    image_array = np.array(input_image)\n",
    "    image_tensor = torch.unsqueeze(torch.transpose(torch.tensor(input_image), 0, 2), 0).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = my_model(image_tensor)\n",
    "\n",
    "    predicted_mask = torch.argmax(output, dim=1).squeeze().numpy()\n",
    "    predicted_mask_rotated = np.rot90(predicted_mask, k=-1)\n",
    "    predicted_mask_final = np.fliplr(predicted_mask_rotated)\n",
    "    \n",
    "    predicted_mask_final = (predicted_mask_final * 255).astype(np.uint8)\n",
    "    return predicted_mask_final\n",
    "\n",
    "# Gradio Interface\n",
    "ui = gr.Interface(\n",
    "    fn=segment_image, \n",
    "    inputs=gr.Image(),\n",
    "    outputs=gr.Image(),\n",
    "    examples=['celeb_inputs/celeb1.jpg', \n",
    "              'celeb_inputs/celeb2.jpg', \n",
    "              'celeb_inputs/celeb3.jpg',\n",
    "              'celeb_inputs/celeb4.jpg',\n",
    "              'celeb_inputs/celeb5.jpg']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eaf1ad3-f72d-407c-bcf3-4bdbf3dc74cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b1088-103d-4d53-b48f-6eff7faeb0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
